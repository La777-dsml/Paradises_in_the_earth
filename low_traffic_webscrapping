!pip install requests beautifulsoup4
import requests
from bs4 import BeautifulSoup
import json

# Reemplaza con la URL del sitio web
url = 'https://www.tomtom.com/traffic-index/ranking/?country=ES'  # Cambia esto con la URL real

# Realiza la solicitud HTTP para obtener el contenido de la página
response = requests.get(url)

if response.status_code == 200:
    # Analiza el contenido HTML con BeautifulSoup
    soup = BeautifulSoup(response.text, 'html.parser')

    # Encuentra el script con el id "__NEXT_DATA__"
    script = soup.find('script', id='__NEXT_DATA__')

    if script:
        # Carga el contenido JSON del script
        json_data = json.loads(script.string)

# ... (código anterior para obtener json_data)

cities = json_data['props']['pageProps']['cities']

for city in cities:
    rank = city.get('rank')
    name = city.get('name')
    if rank is not None and name is not None:
        print(f'Name: {name}, Rank (cities): {rank}')

cities_metro = json_data['props']['pageProps']['citiesMetro']

for city in cities_metro:
    rank = city.get('rank')
    name = city.get('name')
    if rank is not None and name is not None:
        print(f'Name: {name}, Rank: {rank}')

!pip install pandas==2.1.4

import pandas as pd

# ... (código para obtener cities y citiesMetro desde json_data)

data = []
for city in cities:
  rank = city.get('rank')
  name = city.get('name')
  if rank is not None and name is not None:
    data.append({'Name': name, 'Rank (cities)': rank})

for city in cities_metro:
  rank = city.get('rank')
  name = city.get('name')
  if rank is not None and name is not None:
    data.append({'Name': name, 'Rank (citiesMetro)': rank})

df = pd.DataFrame(data)
df.to_excel('cities_ranks.xlsx', index=False)

from google.colab import files
files.download('cities_ranks.xlsx')
