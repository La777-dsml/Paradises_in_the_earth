import requests
from bs4 import BeautifulSoup
import pandas as pd


headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
}

data = []


for page in range(102, 158):
    
    url = f'https://www.iqair.com/mx/world-most-polluted-cities?continent=&country=&state=&sort=-rank&page={page}&perPage=50&cities='

    
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()  

        
        soup = BeautifulSoup(response.text, 'html.parser')

        
        rows = soup.find_all('tr', class_='mat-row')

        
        for row in rows:
            
            cells = row.find_all('td')

            if len(cells) >= 2:
                
                rank = cells[0].text.strip()
                city_name = cells[1].find('div', class_='city-name').text.strip()

                
                data.append({'Rank': rank, 'City': city_name})
    except requests.RequestException as e:
        print(f"Error al realizar la solicitud para la p√°gina {page}: {e}")


if data:
    df = pd.DataFrame(data)

    
    df.to_excel('polluted_cities_ranks.xlsx', index=False)

    print("Datos guardados en polluted_cities_ranks.xlsx")
else:
    print("No se han encontrado datos para guardar.")

from google.colab import files
files.download('polluted_cities_ranks.xlsx')
